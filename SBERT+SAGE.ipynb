{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5054ce37-c1bf-40f7-9550-0ac161ff0317",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports & Standard stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3a3ea6-b9c1-4b02-b0ad-1fc4554b8577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:44:41.932256Z",
     "iopub.status.busy": "2024-05-05T19:44:41.931855Z",
     "iopub.status.idle": "2024-05-05T19:44:43.710255Z",
     "shell.execute_reply": "2024-05-05T19:44:43.709772Z",
     "shell.execute_reply.started": "2024-05-05T19:44:41.932243Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from tqdm.notebook import  trange, tqdm\n",
    "from ogb.linkproppred import Evaluator\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch_geometric.sampler import NegativeSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287a6aa3-a5f5-42cd-bf28-4965069e07ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:44:43.823498Z",
     "iopub.status.busy": "2024-05-05T19:44:43.823421Z",
     "iopub.status.idle": "2024-05-05T19:44:43.825067Z",
     "shell.execute_reply": "2024-05-05T19:44:43.824868Z",
     "shell.execute_reply.started": "2024-05-05T19:44:43.823490Z"
    }
   },
   "outputs": [],
   "source": [
    "# For printing precise tensor values rather than round-off (For Qualitative Analysis)\n",
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b10ed10-260b-4813-ba29-6899f0a945e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:44:43.825625Z",
     "iopub.status.busy": "2024-05-05T19:44:43.825541Z",
     "iopub.status.idle": "2024-05-05T19:44:43.833494Z",
     "shell.execute_reply": "2024-05-05T19:44:43.833122Z",
     "shell.execute_reply.started": "2024-05-05T19:44:43.825616Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010238f-5716-4d9b-851d-04e72d9112ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T19:52:30.345926Z",
     "iopub.status.busy": "2024-04-23T19:52:30.345688Z",
     "iopub.status.idle": "2024-04-23T19:52:30.347514Z",
     "shell.execute_reply": "2024-04-23T19:52:30.347286Z",
     "shell.execute_reply.started": "2024-04-23T19:52:30.345910Z"
    },
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c445ef0-3e22-4c2c-bfd5-02e67e629c72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:44:47.336273Z",
     "iopub.status.busy": "2024-05-05T19:44:47.336059Z",
     "iopub.status.idle": "2024-05-05T19:44:47.340150Z",
     "shell.execute_reply": "2024-05-05T19:44:47.339798Z",
     "shell.execute_reply.started": "2024-05-05T19:44:47.336258Z"
    }
   },
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ff641c-010d-456b-8575-f34e66a3ac81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:44:47.885845Z",
     "iopub.status.busy": "2024-05-05T19:44:47.885448Z",
     "iopub.status.idle": "2024-05-05T19:44:47.888916Z",
     "shell.execute_reply": "2024-05-05T19:44:47.888633Z",
     "shell.execute_reply.started": "2024-05-05T19:44:47.885832Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels*2, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        # x = x_i * x_j\n",
    "        x = torch.concat([x_i,x_j], dim=1)\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086a120-1375-401c-b781-0959f253ef50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9939f2ec-c0f7-4ce1-aaa0-7cc30f055c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:45:21.237841Z",
     "iopub.status.busy": "2024-05-05T19:45:21.237655Z",
     "iopub.status.idle": "2024-05-05T19:45:21.240056Z",
     "shell.execute_reply": "2024-05-05T19:45:21.239750Z",
     "shell.execute_reply.started": "2024-05-05T19:45:21.237826Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS = \"ERNIE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc074a4d-8bff-4161-962d-a23771e3d155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:45:29.348514Z",
     "iopub.status.busy": "2024-05-05T19:45:29.348177Z",
     "iopub.status.idle": "2024-05-05T19:45:30.331689Z",
     "shell.execute_reply": "2024-05-05T19:45:30.331216Z",
     "shell.execute_reply.started": "2024-05-05T19:45:29.348497Z"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.load(\"./Data/Wiki_en_small_MHRWS_1M_ERNIE.pt\")\n",
    "data.num_nodes = data.x.size(0)\n",
    "# data.x = data.x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24fb64f7-9cc0-4450-8c71-96a2053bb83a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:45:33.467513Z",
     "iopub.status.busy": "2024-05-05T19:45:33.467360Z",
     "iopub.status.idle": "2024-05-05T19:45:36.748825Z",
     "shell.execute_reply": "2024-05-05T19:45:36.748162Z",
     "shell.execute_reply.started": "2024-05-05T19:45:33.467503Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(num_val=0.1, num_test=0.2, is_undirected=False, add_negative_train_samples=False)\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a87633d-d2db-43b9-b5fa-d2a7549a3c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:45:39.305533Z",
     "iopub.status.busy": "2024-05-05T19:45:39.305207Z",
     "iopub.status.idle": "2024-05-05T19:45:39.308635Z",
     "shell.execute_reply": "2024-05-05T19:45:39.308425Z",
     "shell.execute_reply.started": "2024-05-05T19:45:39.305517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1000000, 768], edge_index=[2, 9516737], num_nodes=1000000, edge_label=[9516737], edge_label_index=[2, 9516737])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1984ae-9a1c-4008-8603-a1175369baf1",
   "metadata": {},
   "source": [
    "# Negative Sampling & Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e041bff-a6c8-4413-b7d6-596fc1678257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:45:48.546886Z",
     "iopub.status.busy": "2024-05-05T19:45:48.546593Z",
     "iopub.status.idle": "2024-05-05T19:45:48.549270Z",
     "shell.execute_reply": "2024-05-05T19:45:48.548961Z",
     "shell.execute_reply.started": "2024-05-05T19:45:48.546866Z"
    }
   },
   "outputs": [],
   "source": [
    "train_negative_sampling = NegativeSampling(mode='binary', amount=1)\n",
    "val_negative_sampling = NegativeSampling(mode='triplet', amount=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede2e462-629c-42cc-a83c-caecac330aa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:46:40.124646Z",
     "iopub.status.busy": "2024-05-05T19:46:40.124180Z",
     "iopub.status.idle": "2024-05-05T19:46:40.127027Z",
     "shell.execute_reply": "2024-05-05T19:46:40.126744Z",
     "shell.execute_reply.started": "2024-05-05T19:46:40.124617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3072/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b97bc76-518a-4d07-8d58-fec5811ac352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:22.675401Z",
     "iopub.status.busy": "2024-05-05T19:47:22.675214Z",
     "iopub.status.idle": "2024-05-05T19:47:23.003014Z",
     "shell.execute_reply": "2024-05-05T19:47:23.002641Z",
     "shell.execute_reply.started": "2024-05-05T19:47:22.675390Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_NBRS_PER_HOP = [20,20] #20 Nodes will be sampled from the first hop and 20 from second hop\n",
    "TRAIN_BATCH = 1356\n",
    "VAL_BATCH = 2048\n",
    "\n",
    "train_loader = LinkNeighborLoader(train_data, \n",
    "                                  num_neighbors=NUM_NBRS_PER_HOP, # FIX THIS WRT TO NUM_LAYERS\n",
    "                                  batch_size=TRAIN_BATCH,\n",
    "                                  neg_sampling=train_negative_sampling,\n",
    "                                  edge_label_index=train_data.edge_label_index,\n",
    "                                  edge_label=train_data.edge_label,\n",
    "                                  shuffle=True)\n",
    "\n",
    "val_loader = LinkNeighborLoader(val_data, \n",
    "                                  num_neighbors=NUM_NBRS_PER_HOP, #FIX THIS WRT TO NUM_LAYERS\n",
    "                                  batch_size=VAL_BATCH,\n",
    "                                  neg_sampling=val_negative_sampling,\n",
    "                                  edge_label_index=val_data.edge_label_index,\n",
    "                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd50db6-1aba-4836-84fd-a9001ae0fb6a",
   "metadata": {},
   "source": [
    "# Model Object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38317ca8-1786-4754-bf8f-7e1bd788cff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:26.078750Z",
     "iopub.status.busy": "2024-05-05T19:47:26.078602Z",
     "iopub.status.idle": "2024-05-05T19:47:26.081088Z",
     "shell.execute_reply": "2024-05-05T19:47:26.080834Z",
     "shell.execute_reply.started": "2024-05-05T19:47:26.078740Z"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_CHANNELS = 512\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3433844-768a-4669-adfa-9382e1acaf3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:35.771761Z",
     "iopub.status.busy": "2024-05-05T19:47:35.771582Z",
     "iopub.status.idle": "2024-05-05T19:47:35.856658Z",
     "shell.execute_reply": "2024-05-05T19:47:35.856310Z",
     "shell.execute_reply.started": "2024-05-05T19:47:35.771751Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SAGE(data.num_features, HIDDEN_CHANNELS,\n",
    "             HIDDEN_CHANNELS, NUM_LAYERS,\n",
    "             DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b37971-1917-4dd6-a6b9-c9965f9079e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:40.822215Z",
     "iopub.status.busy": "2024-05-05T19:47:40.822067Z",
     "iopub.status.idle": "2024-05-05T19:47:40.825105Z",
     "shell.execute_reply": "2024-05-05T19:47:40.824869Z",
     "shell.execute_reply.started": "2024-05-05T19:47:40.822205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAGE(\n",
       "  (convs): ModuleList(\n",
       "    (0): SAGEConv(768, 512, aggr=mean)\n",
       "    (1): SAGEConv(512, 512, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd11a313-de30-427f-957f-1d0884db2fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:59.242530Z",
     "iopub.status.busy": "2024-05-05T19:47:59.242023Z",
     "iopub.status.idle": "2024-05-05T19:47:59.266350Z",
     "shell.execute_reply": "2024-05-05T19:47:59.266089Z",
     "shell.execute_reply.started": "2024-05-05T19:47:59.242516Z"
    }
   },
   "outputs": [],
   "source": [
    "link_predictor = LinkPredictor(HIDDEN_CHANNELS, 1024, 1,\n",
    "                          4,DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d2afd-b96f-41e1-a6d3-fcb0092c4d28",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1f3c4a6-6733-4b84-9b0c-902ba01c126f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:09.211308Z",
     "iopub.status.busy": "2024-05-05T19:48:09.211076Z",
     "iopub.status.idle": "2024-05-05T19:48:09.215926Z",
     "shell.execute_reply": "2024-05-05T19:48:09.215682Z",
     "shell.execute_reply.started": "2024-05-05T19:48:09.211293Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, link_predictor, train_loader, optimizer, cached_embeddings, GAMMA=2, ALPHA=0.5):\n",
    "    model.train()\n",
    "    link_predictor.train()\n",
    "    total_loss = total_examples = 0\n",
    "\n",
    "    pos_means = []\n",
    "    neg_means = []\n",
    "    for idx,batch in enumerate(tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Sending the batch to device\n",
    "        x, edge_index = batch.x.to(device), batch.edge_index.to(device)\n",
    "        \n",
    "        #Forward Pass through the GNN\n",
    "        embed = model(x, edge_index)\n",
    "        \n",
    "        #Saving the Embeddings to the Cache \n",
    "        # These are only the nodes who's parameterized random k-hop neighbourhood is present in the batch\n",
    "        complete_embeddings = embed[:batch.num_sampled_nodes[0]].cpu()  \n",
    "        # These are the corresponding positions of the embeddings in the global cache\n",
    "        global_indices = batch.n_id[:batch.num_sampled_nodes[0]].cpu()  \n",
    "        # Here we update the cache\n",
    "        cached_embeddings[global_indices] = complete_embeddings \n",
    "\n",
    "        #Extracting Edge_Embeddings for Positive Edges\n",
    "        pos_edges = batch.edge_label_index[:,batch.edge_label.bool()].to(device)\n",
    "        start_node_embeddings, end_node_embeddings = embed[pos_edges[0]], embed[pos_edges[1]]\n",
    "        pos_op = link_predictor(start_node_embeddings, end_node_embeddings)\n",
    "        pos_loss = -(ALPHA * torch.pow(1-pos_op, GAMMA) * torch.log(pos_op + 1e-15)).mean()\n",
    "\n",
    "        #Extracting Edge_Embedding for Negative Edges\n",
    "        neg_edges = batch.edge_label_index[:,~batch.edge_label.bool()].to(device)\n",
    "        start_node_embeddings, end_node_embeddings = embed[neg_edges[0]], embed[neg_edges[1]]\n",
    "        neg_op = link_predictor(start_node_embeddings, end_node_embeddings)\n",
    "        neg_loss = -((1-ALPHA)*torch.pow(neg_op, GAMMA) * torch.log(1 - neg_op + 1e-15)).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(link_predictor.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        num_examples = pos_op.size(0)\n",
    "        batch_loss = loss.item() * num_examples\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        total_examples += num_examples\n",
    "        wandb.log({\"train_loss\":loss.item(), \n",
    "                   \"pos_mean\":pos_op.mean().item(), \n",
    "                   \"neg_mean\":neg_op.mean().item(),\n",
    "                   \"pos_min\":pos_op.min().item(),\n",
    "                   \"neg_max\":neg_op.max().item()\n",
    "                  })\n",
    "    return total_loss/total_examples, cached_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54630a3-6147-4a0f-aae9-fbe6e5c7ecba",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfacedda-a09f-42fb-a3cd-844890aa3c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:10.673957Z",
     "iopub.status.busy": "2024-05-05T19:48:10.673744Z",
     "iopub.status.idle": "2024-05-05T19:48:10.680426Z",
     "shell.execute_reply": "2024-05-05T19:48:10.680096Z",
     "shell.execute_reply.started": "2024-05-05T19:48:10.673943Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(link_predictor, val_loader, cached_embedding, evaluator, log_flag=True):\n",
    "    link_predictor.eval()\n",
    "    pos_preds = []\n",
    "    neg_preds = []\n",
    "    total_loss = total_examples = 0\n",
    "    for idx,batch in enumerate(tqdm(val_loader)):\n",
    "        with torch.no_grad():\n",
    "            #First convert the local node_ids to global node_ids\n",
    "            #For positive edges\n",
    "            global_src_idx = batch.n_id[batch.src_index]\n",
    "            global_dest_idx = batch.n_id[batch.dst_pos_index]\n",
    "            # Here we are reading via cache as we dont need the gradients to flow\n",
    "            start_node_embeddings= cached_embedding[global_src_idx].to(device) \n",
    "            end_node_embeddings  = cached_embedding[global_dest_idx].to(device)\n",
    "            \n",
    "            pos_op = link_predictor(start_node_embeddings, end_node_embeddings)\n",
    "            pos_loss = -torch.log(pos_op + 1e-15).mean()\n",
    "            pos_scores = pos_op.squeeze().cpu()\n",
    "            pos_preds += [pos_scores]\n",
    "\n",
    "            #For negative Edges \n",
    "            all_global_src_idx = batch.n_id[batch.src_index]\n",
    "            \n",
    "            # repeating src for c corruptions per src_index c = batch.dst_neg_index.size(1)\n",
    "            global_src_idx = all_global_src_idx.repeat(batch.dst_neg_index.size(1),1).T.flatten()\n",
    "            global_dest_idx = batch.n_id[batch.dst_neg_index.flatten()]\n",
    "            \n",
    "            # Retrieve node embeddings from cache\n",
    "            start_node_embeddings = cached_embedding[global_src_idx].to(device)\n",
    "            end_node_embeddings = cached_embedding[global_dest_idx].to(device)\n",
    "            \n",
    "            # Pass embeddings through the link predictor\n",
    "            neg_op = link_predictor(start_node_embeddings, end_node_embeddings)\n",
    "            neg_loss = -torch.log(1 - neg_op + 1e-15).mean()\n",
    "            \n",
    "            # Reshape the output predictions to match the original format\n",
    "            neg_scores = neg_op.squeeze().cpu()\n",
    "            neg_preds += [neg_scores]\n",
    "\n",
    "            # Updating Loss  \n",
    "            loss = pos_loss + neg_loss\n",
    "            num_examples = (pos_op.size(0) + neg_op.size(0))/2\n",
    "            batch_loss = loss.item() * num_examples\n",
    "            total_loss += batch_loss\n",
    "            total_examples += num_examples\n",
    "                \n",
    "    pos_pred = torch.cat(pos_preds, dim=0)\n",
    "    neg_pred = torch.cat(neg_preds, dim=0).reshape(pos_pred.size(0),-1)\n",
    "\n",
    "    mrr = evaluator.eval({\n",
    "                'y_pred_pos': pos_pred,\n",
    "                'y_pred_neg': neg_pred,\n",
    "            })['mrr_list'].mean().item()\n",
    "    \n",
    "    wandb.log({\"val_loss\":total_loss, \n",
    "               \"mrr\":mrr\n",
    "              })\n",
    "    return total_loss, mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58566d19-9209-41c4-866d-b9e83591d3f9",
   "metadata": {},
   "source": [
    "# Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b5be487-1154-4c82-88b1-9005db4de7ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:12.264164Z",
     "iopub.status.busy": "2024-05-05T19:48:12.264010Z",
     "iopub.status.idle": "2024-05-05T19:48:12.268554Z",
     "shell.execute_reply": "2024-05-05T19:48:12.268303Z",
     "shell.execute_reply.started": "2024-05-05T19:48:12.264153Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name='ogbl-citation2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e53cc6bf-10bb-4f78-a74c-c80042416669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:13.170814Z",
     "iopub.status.busy": "2024-05-05T19:48:13.170625Z",
     "iopub.status.idle": "2024-05-05T19:48:13.173142Z",
     "shell.execute_reply": "2024-05-05T19:48:13.172873Z",
     "shell.execute_reply.started": "2024-05-05T19:48:13.170801Z"
    }
   },
   "outputs": [],
   "source": [
    "RUNS = 1\n",
    "EPOCHS = 10\n",
    "EVAL_STEP = 1\n",
    "LR = 0.01\n",
    "OUT_CHANNELS = HIDDEN_CHANNELS\n",
    "num_nodes = data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbf60720-2be1-40ea-84c3-b8f0553ca75b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:23.595686Z",
     "iopub.status.busy": "2024-05-05T19:48:23.595545Z",
     "iopub.status.idle": "2024-05-05T19:48:23.723542Z",
     "shell.execute_reply": "2024-05-05T19:48:23.723151Z",
     "shell.execute_reply.started": "2024-05-05T19:48:23.595676Z"
    }
   },
   "outputs": [],
   "source": [
    "cached_embeddings = torch.zeros([num_nodes,HIDDEN_CHANNELS], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdaee3e-c212-4dae-a5f3-3489eb9caec3",
   "metadata": {
    "execution": {
     "execution_failed": "2024-05-05T22:00:57.514Z",
     "iopub.execute_input": "2024-05-05T19:48:39.732476Z",
     "iopub.status.busy": "2024-05-05T19:48:39.732325Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madityakadam\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adi/Desktop/OGB/Wiki/LM_GNN_FT/wandb/run-20240506_011841-l9i4pghs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adityakadam/SBERT%2BSAGE/runs/l9i4pghs/workspace' target=\"_blank\">dark-council-32</a></strong> to <a href='https://wandb.ai/adityakadam/SBERT%2BSAGE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adityakadam/SBERT%2BSAGE' target=\"_blank\">https://wandb.ai/adityakadam/SBERT%2BSAGE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adityakadam/SBERT%2BSAGE/runs/l9i4pghs/workspace' target=\"_blank\">https://wandb.ai/adityakadam/SBERT%2BSAGE/runs/l9i4pghs/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138a001fe58f41d39748398c98868746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59508edac4ac4633b1712f806986d59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88717b107c974cd594267d13d5748dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For run=0 and epoch=0 training loss=0.03231949127207814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6367d6e71742798cd9d0dec83103dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For run=0 and for epoch=0 the val_loss=375979941.66914654 with mrr=0.38483351469039917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c1e1c1fdf940aa9afe67847688d1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For run=0 and epoch=1 training loss=0.023707562000722313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a9c19181f54b5487c08cc0d7ebad6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For run=0 and for epoch=1 the val_loss=404230995.0028391 with mrr=0.39071738719940186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65e61435fd64291893cfcd481b16dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"SBERT+SAGE\",\n",
    "    config={\"RUNS\":RUNS,\n",
    "            \"EPOCHS\":EPOCHS,\n",
    "            \"HIDDEN_CHANNELS\":HIDDEN_CHANNELS,\n",
    "            \"EMBEDDINGS\":EMBEDDINGS,\n",
    "            \"NUM_LAYERS\":NUM_LAYERS,\n",
    "            }\n",
    ") \n",
    "for run in trange(RUNS):\n",
    "    #Re-setting the parameters\n",
    "    model.reset_parameters()\n",
    "    link_predictor.reset_parameters()\n",
    "\n",
    "    #Optimizer\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()) + list(link_predictor.parameters()))\n",
    "    \n",
    "    for epoch in trange(EPOCHS):\n",
    "        loss, cached_embedding = train(model, link_predictor, train_loader, optimizer, cached_embeddings)\n",
    "        print(f\"For {run=} and {epoch=} training {loss=}\")\n",
    "\n",
    "        \n",
    "        if (epoch%EVAL_STEP == 0):\n",
    "            val_loss, mrr  = evaluate(link_predictor, val_loader, cached_embedding, evaluator, log_flag=True)\n",
    "            print(f\"For {run=} and for {epoch=} the {val_loss=} with {mrr=}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
